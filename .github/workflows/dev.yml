name: terraform-dev

on:
  pull_request:
    paths:
      - 'dev/**/*'
      - '.github/workflows/dev.yml'
  push:
    branches: [ main ]
    paths:
      - 'dev/**/*'
      - '.github/workflows/dev.yml'
  workflow_dispatch: {}

env:
  TF_WORKING_DIR: "./dev"

concurrency:
  group: terraform-${{ github.ref }}
  cancel-in-progress: false

permissions:
  id-token: write
  actions: write   # required to manage Actions variables
  contents: read

jobs:
  apply:
    if: ${{ vars.DESTROY_TF_DEV == 'false' }} # env vars are evaluated BEFORE the job. Repo vars are used here.
    runs-on: ubuntu-latest
    environment: dev
    defaults:
      run:
        working-directory: ${{ env.TF_WORKING_DIR }}
    steps:
      - uses: actions/checkout@v4

      #- name: Show OIDC claims
      #  uses: actions/github-script@v7
      #  with:
      #    script: |
      #      const idt = await core.getIDToken('sts.amazonaws.com');
      #      const claims = JSON.parse(Buffer.from(idt.split('.')[1], 'base64').toString());
      #      console.log('aud:', claims.aud);
      #      console.log('sub:', claims.sub);

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEP_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.13.0

      - name: Detect runner egress IP
        run: echo "TF_VAR_github_actions_egress_cidr=$(curl -s https://checkip.amazonaws.com)/32" >> $GITHUB_ENV

      - name: Init
        run: terraform init -input=false

      - name: Fmt
        run: terraform fmt -recursive -check

      - name: Validate
        run: terraform validate

      ###### PLAN
      - name: Check EKS cluster
        id: eks_status
        run: |
          set -euo pipefail
          if aws eks describe-cluster --name dev-dp-001-cluster > /dev/null 2>&1; then
            echo "status=DEPLOYED" >> "$GITHUB_OUTPUT"
          fi

      - name: Make EKS cluster public
        if: steps.eks_status.outputs.status == 'DEPLOYED'
        run: terraform apply -input=false -auto-approve -target=module.eks.aws_eks_cluster.this[0] -target=aws_security_group_rule.github_access -var enable_public_api=true
      
      - name: Plan
        id: plan
        run:  |
          aws eks update-kubeconfig --name dev-dp-001-cluster >/dev/null 2>&1 || true
          if kubectl get ns monitoring >/dev/null 2>&1; then
            # avoid monitoring destroy
            terraform plan -input=false -out=tfplan -var enable_public_api=true -var deploy_monitoring=true
          else
            terraform plan -input=false -out=tfplan -var enable_public_api=true
          fi

      - name: Plan full output
        run: terraform show -no-color tfplan > tfplan.txt

      - name: Plan catch errors
        if: ${{ failure() && steps.plan.outcome == 'failure' }}
        run: |
          set -o pipefail
          terraform plan -no-color -input=false -var enable_public_api=true 2>&1 | tee tfplan.txt

      - name: Upload plan full output artifact
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: ${{ env.TF_WORKING_DIR }}/tfplan.txt

      ###### APPLY
      - name: Apply (with public eks)
        if: ${{ vars.APPLY_TF_DEV == 'true' }}
        run: terraform apply -input=false -auto-approve tfplan

      - name: Deploy Apps
        if: ${{ vars.APPLY_TF_DEV == 'true' }}
        run: terraform apply -input=false -auto-approve -target=kubernetes_manifest.argocd_root_app -var enable_public_api=true -var deploy_apps=true

      - name: Deploy Monitoring Suite
        if: ${{ vars.APPLY_TF_DEV == 'true' }}
        run: |
          if kubectl get ns monitoring >/dev/null 2>&1; then
            echo "Monitoring already deployed â€” skipping."
            exit 0
          fi
          terraform apply -input=false -auto-approve -target=module.monitoring -var enable_public_api=true -var deploy_monitoring=true

      - name: Apply (just make eks private)
        if: ${{ vars.APPLY_TF_DEV == 'true' }}
        run: terraform apply -input=false -auto-approve -target=module.eks.aws_eks_cluster.this[0] -target=aws_security_group_rule.github_access -var enable_public_api=false -var deploy_apps=true

      - name: Sync S3 website
        if: ${{ vars.APPLY_TF_DEV == 'true' }}
        run: aws s3 sync resources/s3_website s3://dp-001-ui.dev.lmv-dev.top --delete

      
  destroy:
    if: ${{ vars.DESTROY_TF_DEV == 'true' }} # env vars are evaluated BEFORE the job. Repo vars are used here.
    runs-on: ubuntu-latest
    environment: dev
    defaults:
      run:
        working-directory: ${{ env.TF_WORKING_DIR }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEP_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.13.0

      - name: Init
        run: terraform init -input=false

      - name: Check EKS cluster
        id: eks_status
        run: |
          set -euo pipefail
          if aws eks describe-cluster --name dev-dp-001-cluster > /dev/null 2>&1; then
            echo "status=DEPLOYED" >> "$GITHUB_OUTPUT"
          fi

      - name: Make EKS cluster public
        if: steps.eks_status.outputs.status == 'DEPLOYED'
        run: terraform apply -input=false -auto-approve -target=module.eks.aws_eks_cluster.this[0] -var "github_actions_egress_cidr=$(curl -s https://checkip.amazonaws.com)/32" -var enable_public_api=true

      - name: Remove ArgoCD finalizer
        if: steps.eks_status.outputs.status == 'DEPLOYED'
        run: |
          aws eks update-kubeconfig --name dev-dp-001-cluster
          kubectl -n argocd patch application root-app-dev -p '{"metadata":{"finalizers":[]}}' --type=merge || true

      - name: Purge ALB Controller resources (ALB+TG+SG)
        run: |
          set -Eeuo pipefail
          MAX_ATTEMPTS=5

          echo "Deleting ALBs..."
          aws elbv2 describe-load-balancers --output json | jq -r '.LoadBalancers[] | select(.LoadBalancerName | startswith("k8s-")) | .LoadBalancerArn' \
          | while read -r arn; do
              [[ -z "$arn" ]] && continue
              aws elbv2 delete-load-balancer --load-balancer-arn "$arn"
            done

          echo "Deleting Target Groups..."
          aws elbv2 describe-target-groups --output json | jq -r '.TargetGroups[] | select(.TargetGroupName | startswith("k8s-")) | .TargetGroupArn' | \
          while read -r tg; do
            [[ -z "$tg" ]] && continue
            ATTEMPTS=0
            while true; do
              if (( ATTEMPTS >= MAX_ATTEMPTS )); then
                echo "Reached max attempts for TG deletion: $tg" >&2
                exit 1
              fi
              aws elbv2 delete-target-group --target-group-arn "$tg" 2> errfile || true
              if [[ -z $(cat errfile) ]]; then echo "Deleted: $tg"; break; fi
              (( ++ATTEMPTS ))
              sleep 20
            done
          done

          echo "Removing backend SG from node groups SG rules..."
          aws ec2 describe-security-group-rules \
            --query "SecurityGroupRules[?Description != null && contains(Description, 'elbv2.k8s.aws/targetGroupBinding=shared')].{sgrid:SecurityGroupRuleId, sgid:GroupId}" | \
            jq -r '.[] | "\(.sgrid) \(.sgid)"' | \
            while read -r sgrid sgid; do
              [[ -z "$sgrid" ]] && continue
              aws ec2 revoke-security-group-ingress --group-id $sgid --security-group-rule-ids $sgrid
            done

          echo "Deleting Security Groups..."
          aws ec2 describe-security-groups --output json | jq -r '.SecurityGroups[] | select(.GroupName | startswith("k8s-")) | .GroupId' | \
          while read -r sg; do
            [[ -z "$sg" ]] && continue
            ATTEMPTS=0
            while true; do
              if (( ATTEMPTS >= MAX_ATTEMPTS )); then
                echo "Reached max attempts for SG deletion: $sg" >&2
                exit 1
              fi
              aws ec2 delete-security-group --group-id "$sg" 2> errfile || true
              if [[ -z $(cat errfile) ]]; then echo "Deleted: $sg"; break; fi
              (( ++ATTEMPTS ))
              sleep 20
            done
          done

      - name: Remove usual EKS blockers from TF State
        run: |
          for resource in \
            kubernetes_namespace_v1.argocd \
            kubernetes_manifest.argocd_root_app \
            helm_release.argocd \
            helm_release.aws_load_balancer_controller \
            helm_release.metrics_server \
            module.monitoring[0].kubernetes_namespace_v1.monitoring \
            module.monitoring[0].helm_release.victoria_metrics \
            module.monitoring[0].helm_release.vmagent \
            module.monitoring[0].helm_release.grafana \
            module.monitoring[0].helm_release.kube_state_metrics \
            module.monitoring[0].helm_release.node_exporter \
            module.monitoring[0].helm_release.loki \
            module.monitoring[0].helm_release.promtail
          do
            terraform state rm "$resource" || true
          done

      - name: Destroy Infrastructure
        run: terraform destroy -input=false -auto-approve

      - name: Cleanup dangling PVC EBS volumes
        run: |
          VOLUMES=$(aws ec2 describe-volumes --filters Name=status,Values=available Name=tag:Name,Values='*pvc*' --query "Volumes[].VolumeId" --output text)
          if [ -n "$VOLUMES" ]; then
            for vol in $VOLUMES; do
              aws ec2 delete-volume --volume-id "$vol"
            done
          fi

      - name: Reset destroy flag
        env:
          GH_TOKEN: ${{ secrets.TF_GA_PAT }}
        run: gh variable set DESTROY_TF_DEV --body "false" --repo "${{ github.repository }}" 
